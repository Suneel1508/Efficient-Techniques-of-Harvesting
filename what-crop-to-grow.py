# %%
"""
# CROP RECOMMENDATION SYSTEM 
"""

# %%
"""
## AIM

Precision agirculture is in trend nowadays. Precision agriculture is a modern farming technique that uses the data of soil charachteristics, soil types, crop yield data, weather conditions and suggests the farmers with the most optimal crop to grow in their farms for maximum yield and profit. This technique can reduce the crop failures and will help the farmers to take informed decision about their farming strategy.

In order to mitigate the agrarian crisis in the current status quo, there is a need for better recommendation systems to alleviate the crisis by helping the farmers to make an informed decision before starting the cultivation of crops.
"""

# %%
"""
# Goal ðŸŽ¯
**To recommend optimum crops to be cultivated by farmers based on several parameters and help them make an informed decision before cultivation**
"""

# %%
"""
# About the data
"""

# %%
"""
The data used in this project is made by augmenting and combining various publicly available datasets of India like weather, soil, etc. You can access the dataset [here](https://www.kaggle.com/atharvaingle/crop-recommendation-dataset). This data is relatively simple with very few but useful features unlike the complicated features affecting the yield of the crop.

The data have Nitrogen, Phosphorous, Pottasium and pH values of the soil. Also, it also contains the humidity, temperature and rainfall required for a particular crop. 
"""

# %%
# Importing libraries

from __future__ import print_function
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report
from sklearn import metrics
from sklearn import tree
import warnings
warnings.filterwarnings('ignore')

# %%
df = pd.read_csv("crop.csv")

# %%
df.head()

# %%
df.tail()

# %%
df.size

# %%
df.shape

# %%
df.columns

# %%
df['label'].unique()

# %%
df.dtypes

# %%
df['label'].value_counts()

# %%
sns.heatmap(df.corr(),annot=True)

# %%
"""
### Seperating features and target label
"""

# %%
features = df[['N', 'P','K','temperature', 'humidity', 'ph', 'rainfall']]
target = df['label']
labels = df['label']

# %%
# Initializing empty lists to append all model's name and corresponding name
acc = []
model = []

# %%
# Splitting into train and test data

from sklearn.model_selection import train_test_split
Xtrain, Xtest, Ytrain, Ytest = train_test_split(features,target,test_size = 0.2,random_state =2)

# %%
"""
# Decision Tree
"""

# %%
from sklearn.tree import DecisionTreeClassifier

DecisionTree = DecisionTreeClassifier(criterion="entropy",random_state=2,max_depth=5)

DecisionTree.fit(Xtrain,Ytrain)

predicted_values = DecisionTree.predict(Xtest)
x = metrics.accuracy_score(Ytest, predicted_values)
acc.append(x)
model.append('Decision Tree')
print("DecisionTrees's Accuracy is: ", x*100)

print(classification_report(Ytest,predicted_values))

# %%
from sklearn.model_selection import cross_val_score

# %%
# Cross validation score (Decision Tree)
score = cross_val_score(DecisionTree, features, target,cv=5)

# %%
score

# %%
"""
### Saving trained Decision Tree model
"""

# %%
"""
# Guassian Naive Bayes
"""

# %%
from sklearn.naive_bayes import GaussianNB

NaiveBayes = GaussianNB()

NaiveBayes.fit(Xtrain,Ytrain)

predicted_values = NaiveBayes.predict(Xtest)
x = metrics.accuracy_score(Ytest, predicted_values)
acc.append(x)
model.append('Naive Bayes')
print("Naive Bayes's Accuracy is: ", x)

print(classification_report(Ytest,predicted_values))

# %%
# Cross validation score (NaiveBayes)
score = cross_val_score(NaiveBayes,features,target,cv=5)
score

# %%
"""
### Saving trained Guassian Naive Bayes model
"""

# %%
"""
# Support Vector Machine (SVM)
"""

# %%
from sklearn.svm import SVC

SVM = SVC(gamma='auto')

SVM.fit(Xtrain,Ytrain)

predicted_values = SVM.predict(Xtest)

x = metrics.accuracy_score(Ytest, predicted_values)
acc.append(x)
model.append('SVM')
print("SVM's Accuracy is: ", x)

print(classification_report(Ytest,predicted_values))

# %%
# Cross validation score (SVM)
score = cross_val_score(SVM,features,target,cv=5)
score

# %%
"""
# Logistic Regression
"""

# %%
from sklearn.linear_model import LogisticRegression

LogReg = LogisticRegression(random_state=2)

LogReg.fit(Xtrain,Ytrain)

predicted_values = LogReg.predict(Xtest)

x = metrics.accuracy_score(Ytest, predicted_values)
acc.append(x)
model.append('Logistic Regression')
print("Logistic Regression's Accuracy is: ", x)

print(classification_report(Ytest,predicted_values))

# %%
# Cross validation score (Logistic Regression)
score = cross_val_score(LogReg,features,target,cv=5)
score

# %%
"""
### Saving trained Logistic Regression model
"""

# %%
"""
# Random Forest
"""

# %%
from sklearn.ensemble import RandomForestClassifier

RF = RandomForestClassifier(n_estimators=20, random_state=0)
RF.fit(Xtrain,Ytrain)

predicted_values = RF.predict(Xtest)

x = metrics.accuracy_score(Ytest, predicted_values)
acc.append(x)
model.append('RF')
print("RF's Accuracy is: ", x)

print(classification_report(Ytest,predicted_values))

# %%
# Cross validation score (Random Forest)
score = cross_val_score(RF,features,target,cv=5)
score

# %%
"""
### Saving trained Random Forest model
"""

# %%
import pickle
# Dump the trained Naive Bayes classifier with Pickle
RF_pkl_filename = 'RandomForest.pkl'
# Open the file to save as pkl file
RF_Model_pkl = open(RF_pkl_filename, 'wb')
pickle.dump(RF, RF_Model_pkl)
# Close the pickle instances
RF_Model_pkl.close()

# %%
"""
# XGBoost
"""

# %%
import xgboost as xgb
XB = xgb.XGBClassifier()
XB.fit(Xtrain,Ytrain)

predicted_values = XB.predict(Xtest)

x = metrics.accuracy_score(Ytest, predicted_values)
acc.append(x)
model.append('XGBoost')
print("XGBoost's Accuracy is: ", x)

print(classification_report(Ytest,predicted_values))

# %%
# Cross validation score (XGBoost)
score = cross_val_score(XB,features,target,cv=5)
score

# %%
"""
### Saving trained XGBoost model
"""

# %%
"""
## Accuracy Comparison
"""

# %%
plt.figure(figsize=[10,5],dpi = 100)
plt.title('Accuracy Comparison')
plt.xlabel('Accuracy')
plt.ylabel('Algorithm')
sns.barplot(x = acc,y = model,palette='dark')

# %%
accuracy_models = dict(zip(model, acc))
for k, v in accuracy_models.items():
    print (k, '-->', v)

# %%
"""
## Making a prediction
"""

# %%
data = np.array([[104,18, 30, 23.603016, 60.3, 6.7, 140.91]])
prediction = RF.predict(data)
print(prediction)

# %%
data = np.array([[83, 45, 60, 28, 70.3, 7.0, 150.9]])
prediction = RF.predict(data)
print(prediction)

# %%
